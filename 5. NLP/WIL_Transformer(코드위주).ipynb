{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PQSnsGeA2OH"
   },
   "source": [
    "# 트랜스포머 (Transformer)\n",
    "\n",
    "* 참고: https://wikidocs.net/31379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbQ-h_XxBAiq"
   },
   "source": [
    "* attention mechanism은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n",
    "* attention mechanism을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n",
    "* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDiFPIdUBBS2"
   },
   "source": [
    "## 포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLqHf_4SEWoa"
   },
   "source": [
    "* 기존의 RNN은 단어의 위치를 따라 순차적으로 입력받아 단어의 위치정보를 활용할 수 있었음\n",
    "* 트랜스포머의 경우, RNN을 활용하지 않았기 때문에 단어의 위치정보를 다른 방식으로 줄 필요가 있음\n",
    "* 이를 위해 **각 단어의 임베딩 벡터에 위치 정보들을 더하게 되는데** 이를 포지셔널 인코딩이라 함\n",
    "* 보통 포지셔널 인코딩은 sin, cos을 이용하여 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SiO5c_HIFBAk"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(dim, sentence_length):\n",
    "    encoded_vec = np.array([pos / np.power(10000, 2 * i / dim) for pos in range(sentence_length) for i in range(dim)])\n",
    "    encoded_vec[::2] = np.sin(encoded_vec[::2])\n",
    "    encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n",
    "    \n",
    "    return tf.constant(encoded_vec.reshape([sentence_length, dim]), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "099gUUxhAgy3"
   },
   "source": [
    "## 레이어 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCdips98yPuH"
   },
   "source": [
    "*  레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화함\n",
    "*  해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TSJjxF86Aeg3"
   },
   "outputs": [],
   "source": [
    "def layer_norm(inputs, eps = 1e-6):\n",
    "    feature_shape = inputs.get_shape()[-1:]\n",
    "    \n",
    "    mean = tf.keras.backend.mean(inputs, [-1], keepdims = True)\n",
    "    std = tf.keras.backend.std(inputs, [-1], keepdims = True)\n",
    "    \n",
    "    beta = tf.Variable(tf.zeros(feature_shape), trainable = False)\n",
    "    gamma = tf.Variable(tf.ones(feature_shape), trainable = False)\n",
    "    \n",
    "    return gamma * (inputs - mean) / (std + eps) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "km9ORxIun-MU"
   },
   "outputs": [],
   "source": [
    "def sublayer_connection(inputs, sublayer, dropout = 0.2):\n",
    "    outputs = layer_norm(inputs + tf.keras.layers.Dropout(dropout)(sublayer))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ppb7IxJ3diMC"
   },
   "source": [
    "## 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JaU6MHgy9V2"
   },
   "source": [
    "\n",
    "\n",
    "*   트랜스포머 모델의 핵심이 되는 부분\n",
    "*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n",
    "  1.   multi-head attention\n",
    "      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n",
    "      *  마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n",
    "      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n",
    "  2.   self attention\n",
    "      *   일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n",
    "      *   이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n",
    "      *   반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n",
    "      *   이는 입력 문장 내 단어간의 어텐션을 의미함\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRyL0KDXi6ej"
   },
   "source": [
    "### scaled-dot product attention 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HtmcgRR3Cr-"
   },
   "source": [
    "* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n",
    "* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n",
    "* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ALEMzi4fdiSQ"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, masked = False):\n",
    "    key_dim_size = float(key.get_shape().as_list()[-1])\n",
    "    key = tf.transpose(key, perm = [0, 2, 1])\n",
    "    \n",
    "    outputs  = tf.matmul(query, key) / tf.sqrt(key_dim_size)\n",
    "    \n",
    "    if masked:\n",
    "        diag_vals = tf.ones_like(outputs[0, :, :])\n",
    "        trill = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()\n",
    "        masks = tf.tile(tf.expand_dims(trill, 0), [tf.shape(outputs)[0], 1, 1])\n",
    "        paddings = tf.ones_like(masks) * (-2**30)\n",
    "        outputs = tf.where(tf.equal(masks, 0), paddings, outputs)\n",
    "        \n",
    "    attention_map = tf.nn.softmax(outputs)\n",
    "    \n",
    "    return tf.matmul(attention_map, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr20BxvVi-8b"
   },
   "source": [
    "### multi-head attention 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb5qflUH14-H"
   },
   "source": [
    "* multi-head attention의 구현 과정\n",
    "  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n",
    "  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n",
    "  3. 분리한 행렬들에 대해 각각 어텐션을 수행\n",
    "  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ooc3FAdQi_Gz"
   },
   "outputs": [],
   "source": [
    "def multi_head_attention(query, key, value, num_units, heads, masked = False):\n",
    "    # 1. 행렬 생성\n",
    "    query = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(query)\n",
    "    key = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(key)\n",
    "    value = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(value)\n",
    "    \n",
    "    # 2. 분리 & concat\n",
    "    query = tf.concat(tf.split(query, heads, axis = -1), axis = 0)\n",
    "    key = tf.concat(tf.split(key, heads, axis = -1), axis = 0)\n",
    "    value = tf.concat(tf.split(value, heads, axis = -1), axis = 0)\n",
    "    \n",
    "    # 3. 각각 어텐션 수행\n",
    "    attention_map = scaled_dot_product_attention(query, key, value, masked)\n",
    "    attn_outputs = tf.concat(tf.split(attention_map, heads, axis = 0), axis = -1)\n",
    "    attn_outputs = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(attn_outputs)\n",
    "    \n",
    "    return attn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78Zn5-fYITD4"
   },
   "source": [
    "## 포지션-와이즈 피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xxeG2xvo3ZN"
   },
   "source": [
    "\n",
    "\n",
    "*   multi-head attention의 결과인 행렬을 입력받아 연산\n",
    "*   일반적인 완전 연결 신경망(Dense layer)를 사용\n",
    "*   position-wise FFNN은 인코더와 디코더에 모두 존재\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0tSFd5OaITJ0"
   },
   "outputs": [],
   "source": [
    "def feed_forward(inputs, num_units):\n",
    "    feature_shape = inputs.get_shape()[-1]\n",
    "    inner_layer = tf.keras.layers.Dense(num_units, activaiton = tf.nn.relu)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(feature_shape)(inner_layer)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuccViYgBK6v"
   },
   "source": [
    "## 인코더\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tG3MH0n1JVLz"
   },
   "source": [
    "* 인코더는 하나의 어텐션을 사용\n",
    "  + encoder self-attention (multi-head self-attention과 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m5T0pzBoAnn3"
   },
   "outputs": [],
   "source": [
    "def encoder_module(inputs, model_dim, ffn_dim, heads):\n",
    "    self_attn = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads))\n",
    "    outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
    "    return outputs\n",
    "\n",
    "def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n",
    "    outputs = inputs\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_module(outputs, model_dim, ffn_dim, heads)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcgHRcTEBQqg"
   },
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNj-6FLQwT4-"
   },
   "source": [
    "* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n",
    "  1. masked decoder self-attention\n",
    "  2. encoder-decoder attention\n",
    "  3. position-wise FFNN\n",
    "\n",
    "* 디코더에서는 2종류의 어텐션을 사용\n",
    "  1.   masked decoder self-attention\n",
    "    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n",
    "    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n",
    "    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n",
    "  2.   encoder-decoder attention\n",
    "    *   앞서 설명한 multi-head attention과 동일\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2B05wr7aARcT"
   },
   "outputs": [],
   "source": [
    "def decoder_module(inputs, encoder_outputs, model_dim, ffn_dim, heads):\n",
    "    masked_self_attn = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads, masked = True))\n",
    "    self_attn = sublayer_connection(masked_self_attn, multi_head_attention(masked_self_attn, \n",
    "                                                                           encoder_outputs, \n",
    "                                                                           encoder_outputs, \n",
    "                                                                           model_dim,\n",
    "                                                                          model_dim,\n",
    "                                                                          heads))\n",
    "    outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
    "    return outputs\n",
    "\n",
    "def decoder(inputs, encoder_outputs, model_dim, ffn_dim, heads, num_layers):\n",
    "    outputs = inputs\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_module(outputs, encoder_outputs, model_dim, ffn_dim, heads)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtztlyUB1ERS"
   },
   "source": [
    "## 트랜스포머를 활용한 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CGUIAzv6eWs"
   },
   "source": [
    "### konlpy 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae0mHT49v5gy"
   },
   "source": [
    "*    한글을 처리하기 위해 konlpy 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8yf75uG6hBW",
    "outputId": "b4628177-043f-4087-dd1a-42a7782db8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4 MB 4.0 MB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 22.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 4.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUMXvK5H1G9H"
   },
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miXrjR316mNb"
   },
   "source": [
    "* 처리에 필요한 각종 변수 선언\n",
    "* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SMjn5PfE1GZR"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "filters = \"([~.,!?\\\"':;)(])\"\n",
    "PAD = '<PADDING>'\n",
    "STD = '<START>'\n",
    "END = '<END>'\n",
    "UNK = '<UNKNOWN>'\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmRFuH2r6oNJ"
   },
   "source": [
    "* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CmrmdXkePWYb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_paht):\n",
    "    data_df = pd.read_csv(data_path, header = 0)\n",
    "    \n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "    train_input, eval_input, train_label, eval_label = train_test_split(question, answer, test_size = .33, random_state = 111)\n",
    "    return train_input, eval_input, train_label, eval_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHuOJHPtPXqq"
   },
   "source": [
    "* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QtQL-AP06oSa"
   },
   "outputs": [],
   "source": [
    "def load_vocab(data_path):\n",
    "    data_df = pd.read_csv(data_path, encoding = 'utf-8')\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "    if tokenize_as_morph:\n",
    "        question = prepro_like_morphlized(question)\n",
    "        answer = prepro_like_morphlized(answer)\n",
    "        \n",
    "    data = []\n",
    "    data.extend(question)\n",
    "    data.extend(answer)\n",
    "    words = data_tokenizer(data)\n",
    "    words = list(set(words))\n",
    "    words[:0] = MARKER\n",
    "    \n",
    "    char2idx = {char : idx for idx, char in enumerate(words)}\n",
    "    idx2char = {idx : char for idx, char in enumerate(words)}\n",
    "    \n",
    "    return char2idx, idx2char, len(char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wYtpjv76r5q"
   },
   "source": [
    "* 문자열 데이터를 학습에 사용될 수 있도록 변현하는 `prepro_like_morphlized()` 함수 선언\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-bQ3FOva6tg6"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "def prepro_like_morphlized(data):\n",
    "    morph_analyzer = Okt()\n",
    "    result_data = list()\n",
    "    \n",
    "    for seq in data:\n",
    "        morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n",
    "        result_data.append(morphlized_seq)\n",
    "        \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhsVp4pWPTR3"
   },
   "source": [
    "* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "otLI_RUfPR_g"
   },
   "outputs": [],
   "source": [
    "def data_tokenizer(data):\n",
    "  words = []\n",
    "\n",
    "  for sentence in data:\n",
    "    sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "    for word in sentence.split():\n",
    "      words.append(word)\n",
    "\n",
    "    return [word for word in words if word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkKPA-Mx6uaC"
   },
   "source": [
    "* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jK-yeSThPGsa"
   },
   "outputs": [],
   "source": [
    "def enc_processing(value, dictionary):\n",
    "  sequences_input_index = []\n",
    "  sequences_length = []\n",
    "\n",
    "  if tokenize_as_morph:\n",
    "    value = prepro_like_morphlized(value)\n",
    "\n",
    "  for sequence in value:\n",
    "    sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "    sequence_index = []\n",
    "\n",
    "    for word in sequence.split():\n",
    "      if dictionary.get(word) is not None:\n",
    "        sequence_index.extend([dictionary[word]])\n",
    "      else:\n",
    "        sequence_index.extend([dictionary[UNK]])\n",
    "\n",
    "    if len(sequence_index) > max_len:\n",
    "      sequence_index = sequence_index[:max_len]\n",
    "    sequences_length.append(len(sequence_index))\n",
    "    sequence_index +=  (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
    "    sequences_input_index.append(sequence_index)\n",
    "\n",
    "  return np.asarray(sequences_input_index), sequences_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4mM57_FPIg7"
   },
   "source": [
    "* decoder의 입력을 구성하기 위한 함수 `dec_input_processing()` 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cX_NpcTq6vw6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otsTEt4FPLJX"
   },
   "source": [
    "* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeP0PWHEPMma"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb9vVUng6xDq"
   },
   "source": [
    "* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n",
    "* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n",
    "* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAlKV4xF62Uf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is-GhUDN62xC"
   },
   "source": [
    "* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n",
    "* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCfwWXhb64Cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwp9Nnwz7UoG"
   },
   "source": [
    "* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\n",
    "* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-T536MdU7Taq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cVd7AOKinqn"
   },
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqLJ0a6r49yi"
   },
   "source": [
    "* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNeeXoZginvj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7PrLEWE1JCs"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy_Opm_A7DKC"
   },
   "source": [
    "*   필요한 각종 인자들을 설정\n",
    "*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKGYuqmH6_kj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaXalEy57ODq"
   },
   "source": [
    "*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n",
    "*   평가 데이터에도 동일하게 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWlgWWIq1KSh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZGgZzWs7Mr7"
   },
   "source": [
    "* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n",
    "* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9vjc3Ck7F4J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNcrVf2z1LSM"
   },
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5lY9DrW8eSK"
   },
   "source": [
    "* 학습한 모델을 사용해 챗봇을 사용\n",
    "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
    "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9IQaBx4Qw8J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjHZKvJ31MAU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mjRZwyLQ_gP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7AJCsXRTqJx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M8mfoUfeAWQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5mrdGRaem6v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "_13 트랜스포머 (Transformer).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
