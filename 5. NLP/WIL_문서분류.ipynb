{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7b1990",
   "metadata": {},
   "source": [
    "# 문서 분류(Document Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7a1f4",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29060a6",
   "metadata": {},
   "source": [
    "* 문서 분류에 필요한 데이터는 `scikit-learn`이 제공하는 20개의 주제를 가지는 뉴스그룹 데이터를 사용\n",
    "* 텍스트는 `CounterVectorizer`를 거쳐 DTM으로 변환\n",
    "* DTM 행렬은 문서에 등장하는 단어들을 빈도 수 별로 표현한 행렬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6584cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7919, 130107) (7919,) (3395, 130107) (3395,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news = fetch_20newsgroups()\n",
    "\n",
    "x = news.data\n",
    "y = news.target\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .3)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57562f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56979)\t1\n",
      "  (0, 85354)\t1\n",
      "  (0, 114688)\t2\n",
      "  (0, 111322)\t1\n",
      "  (0, 123984)\t1\n",
      "  (0, 37780)\t2\n",
      "  (0, 68532)\t11\n",
      "  (0, 114731)\t5\n",
      "  (0, 90379)\t1\n",
      "  (0, 89362)\t9\n",
      "  (0, 76032)\t1\n",
      "  (0, 123292)\t1\n",
      "  (0, 65798)\t5\n",
      "  (0, 80638)\t1\n",
      "  (0, 89860)\t6\n",
      "  (0, 114455)\t16\n",
      "  (0, 68766)\t3\n",
      "  (0, 115475)\t14\n",
      "  (0, 32311)\t8\n",
      "  (0, 74693)\t2\n",
      "  (0, 50111)\t1\n",
      "  (0, 66608)\t9\n",
      "  (0, 73201)\t1\n",
      "  (0, 37565)\t2\n",
      "  (0, 90252)\t5\n",
      "  :\t:\n",
      "  (0, 127861)\t1\n",
      "  (0, 56838)\t1\n",
      "  (0, 115047)\t1\n",
      "  (0, 112197)\t1\n",
      "  (0, 71935)\t1\n",
      "  (0, 84456)\t1\n",
      "  (0, 69377)\t1\n",
      "  (0, 69751)\t1\n",
      "  (0, 116094)\t1\n",
      "  (0, 58670)\t1\n",
      "  (0, 9701)\t1\n",
      "  (0, 59449)\t1\n",
      "  (0, 111228)\t1\n",
      "  (0, 119179)\t1\n",
      "  (0, 59040)\t1\n",
      "  (0, 60606)\t1\n",
      "  (0, 100137)\t1\n",
      "  (0, 44869)\t2\n",
      "  (0, 97964)\t3\n",
      "  (0, 56261)\t1\n",
      "  (0, 74335)\t1\n",
      "  (0, 59142)\t1\n",
      "  (0, 60611)\t2\n",
      "  (0, 110401)\t1\n",
      "  (0, 38255)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f5328",
   "metadata": {},
   "source": [
    "## scikit-learn을 이용한 문서 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94656814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17635e08",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b1a6d",
   "metadata": {},
   "source": [
    "* Logistic Regression은 특성상 다중 분류에는 적합하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baca5c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8698085419734904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train , y_train)\n",
    "pred = LR.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd30232",
   "metadata": {},
   "source": [
    "### 서포트벡터머신(Support Vector Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412da350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809720176730486\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel = 'linear')\n",
    "SVM.fit(x_train, y_train)\n",
    "pred = SVM.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c32b1",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "- 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
    "- 모든 특성들이 독립임을 가정 (naive 가정)\n",
    "- 입력 특성에 따라 3개의 분류기 존재\n",
    "    - 가우시안 나이브 베이즈 분류기\n",
    "    - 베르누이 나이브 베이즈 분류기\n",
    "    - 다항 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693163d9",
   "metadata": {},
   "source": [
    "#### DTM을 이용한 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74999fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262150220913107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(x_train ,y_train)\n",
    "pred = NB.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc30bb",
   "metadata": {},
   "source": [
    "#### tf-idf를 이용한 정확도 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8172f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206185567010309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tf = tfidf.fit_transform(x_train)\n",
    "x_test_tf = tfidf.transform(x_test)\n",
    "\n",
    "NB.fit(x_train_tf, y_train)\n",
    "pred = NB.predict(x_test_tf)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97009e",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "- 분류와 회귀에 사용되는 지도학습 방법\n",
    "- 데이터 특성으로부터 추론된 결정규칙을 통해 값을 예측\n",
    "- **if-then-else** 결정규칙을 통해 데이터학습\n",
    "- 트리의 깊이가 깊을수록 복잡한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebba62a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6200294550810015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train, y_train)\n",
    "pred = DT.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c8509",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "- 트리기반의 앙상블 기법\n",
    "- 분류에 있어서 다른 알고리즘보다 좋은 예측 성능을 보여준다.\n",
    "- XGBoost는 GBM기반이지만, GBM의 단점인 느린 수행 시간과 과적합 규제 부재 등의 문제를 해결\n",
    "- 병렬 CPU환경에서 빠르게 학습 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089c1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec8aa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7098674521354934\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 30, learning_rate = 0.05, max_depth = 3)\n",
    "xgb.fit(x_train, y_train)\n",
    "pred = xgb.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d65ff0",
   "metadata": {},
   "source": [
    "## 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ea610",
   "metadata": {},
   "source": [
    "* 일반 검증은 학습 데이터가 테스트 데이터로 사용되지 않음\n",
    "* 교차 검증은 데이터를 n개의 집합으로 나누어 정확도를 계산해 학습 데이터로 사용된 데이터도 테스트 데이터로 사용\n",
    "* 교차 검증을 사용하면 일반 검증보다 모델의 일반화가 잘 되어 있는지 평가 가능\n",
    "* 앞서 구성한 나이브 베이즈 모델을 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8137e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83870968 0.83826779 0.82368537 0.83031374 0.83642794] 0.833480903927519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(NB, x, y, cv = 5)\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1bdbd",
   "metadata": {},
   "source": [
    "* 교차 검증을 통해 일반 검증보다 좀 더 일반화된 모델 생성 가능\n",
    "* 교차 검증은 일반 검증에 비해 n번 검증을 해 비용이 더 많이 소요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d6136",
   "metadata": {},
   "source": [
    "## 정밀도와 재현률 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf64ff",
   "metadata": {},
   "source": [
    "* 정밀도(precision)는 양성 클래스(정답)으로 예측한 샘플이 양성 클래스일 확률을 의미\n",
    "* 모델이 얼마나 양성 클래스를 잘 예측하는지를 나타냄\n",
    "* 재현률(recall)은 양성 클래스인 샘플에서 모델이 양성 클래스로 예측한 샘플 비율을 의미하며, 모델이 얼마나 실제 상황을 재현하는지를 나타냄\n",
    "* 정밀도와 재현율의 가중조화평균인 F1-score라는 지표는 정확도에 비해 더 효과적인 모델 분석 지표로 알려져 있음\n",
    "* 직접 계산할 수도 있으나, scikit-learn은 이를 편리하게 계산해주는 함수를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7eefb8",
   "metadata": {},
   "source": [
    "* 다중 클래스 분류 문제에서 정밀도와 재현률을 계산할 때는 클래스간의 지표를 어떻게 합칠지 지정 필요\n",
    "\n",
    "  * None - 클래스간 지표를 합치지 말고 그대로 출력\n",
    "  * micro - 정밀도와 재현률이 같음, 이로 인해 f1-score도 정밀도, 재현률과 동일\n",
    "  * macro - 클래스간 지표를 단순 평균한 값\n",
    "  * weighted - 클래스간 지표를 가중 평균한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45fb8e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7098674521354934 0.7098674521354934 0.7098674521354934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(pred, y_test, average = 'micro')\n",
    "recall = recall_score(pred, y_test, average = 'micro')\n",
    "f1 = f1_score(pred, y_test, average = 'micro')\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd31097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7064326500181225 0.741184927468317 0.7154660030527771\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(pred, y_test, average = 'macro')\n",
    "recall = recall_score(pred, y_test, average = 'macro')\n",
    "f1 = f1_score(pred, y_test, average = 'macro')\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b035a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7163730046598048 0.7098674521354934 0.7026096275243655\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(pred, y_test, average = 'weighted')\n",
    "recall = recall_score(pred, y_test, average = 'weighted')\n",
    "f1 = f1_score(pred, y_test, average = 'weighted')\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8b43c",
   "metadata": {},
   "source": [
    "## 그리드 검색을 이용한 파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f12c74",
   "metadata": {},
   "source": [
    "* 그리드 검색을 사용하면 분류기에 사용하는 파라미터 최적화 가능\n",
    "* 그리드 검색을 통해 앞서 구성한 나이브 베이즈 모델의 'alpha' 파라미터를 최적화시키는 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005194e6",
   "metadata": {},
   "source": [
    "* `estimator`: 사용 모델 객체     \n",
    "* `param_grid`: 사용 객체:지정 파라미터 리스트로 구성된 딕셔너리    \n",
    "* `scoring`: 최적화하고자 하는 성능 지표   \n",
    "* `cv`: 교차 검증 분할 개수      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e234536d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8914616353144439\n",
      "{'alpha': 5e-05}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GS = GridSearchCV(estimator = NB, param_grid = {'alpha' : [0.00005, 0.0005, 0.001]}, scoring = 'accuracy', cv = 10)\n",
    "GS.fit(x, y)\n",
    "\n",
    "print(GS.best_score_)\n",
    "print(GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abf55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
