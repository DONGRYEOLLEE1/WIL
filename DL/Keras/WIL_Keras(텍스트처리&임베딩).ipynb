{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac370c9",
   "metadata": {},
   "source": [
    "# 케라스 텍스트 처리 및 임베딩\n",
    "\n",
    "- 코드 참조: 케라스 창시자에게 배우는 딥러닝\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a28a4",
   "metadata": {},
   "source": [
    "## 용어 설명\n",
    "\n",
    "- `토큰(token)`\n",
    "  - 텍스트를 나누는 단위\n",
    "\n",
    "  - 토큰화(tokenization): 토큰으로 나누는 작업\n",
    "\n",
    "- `n-gram`\n",
    "  - 문장에서 추출한 N개(또는 그 이하)의 연속된 단어 그룹\n",
    "\n",
    "  - 같은 개념이 '문자'에도 적용가능\n",
    "\n",
    "  <img src=\"https://www.sqlservercentral.com/wp-content/uploads/legacy/0bf6a2bd621db172dba029ce3c712280a3f6aab3/29444.jpg\">\n",
    "\n",
    "  <sub>출처: https://www.sqlservercentral.com/articles/nasty-fast-n-grams-part-1-character-level-unigrams</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a433c4f",
   "metadata": {},
   "source": [
    "## 문자 수준 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237a860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['The cat sat on the mat.',\n",
    "          'The dog ate my homeworks.']\n",
    "\n",
    "token_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0eb88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "\n",
    "max_len = 10\n",
    "results = np.zeros(shape = (len(samples), max_len,\n",
    "                           max(token_index.values()) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27232133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_len]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1.\n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2519318",
   "metadata": {},
   "source": [
    "## 케라스를 사용한 단어 수준 원-핫 인코딩\n",
    "\n",
    "- `fit_on_texts()`\n",
    "\n",
    "- `texts_to_sequences()`\n",
    "\n",
    "- `texts_to_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00926b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b9053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "samples = ['The cat sat on the mat.',\n",
    "          'The dog ate my homeworks.']\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# 텍스트를 sequence형태로 변환\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "# one-hot\n",
    "ohe_results = tokenizer.texts_to_matrix(samples, mode = 'binary')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f1ddcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740c4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000)\n",
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(ohe_results.shape)\n",
    "print(ohe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "267bc91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'mat': 5,\n",
       " 'dog': 6,\n",
       " 'ate': 7,\n",
       " 'my': 8,\n",
       " 'homeworks': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17663484",
   "metadata": {},
   "source": [
    "### 토큰화 예제\n",
    "\n",
    "- `OOV` : Out of Vocabulary\n",
    "  - 새로운 문장에서 기존에 토큰화한 문장에 존재하지 않으면 OOV로 대체됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc81f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20cec104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, \"i'm\": 2, 'the': 3, 'student': 4, 'smartest': 5, 'best': 6}\n"
     ]
    }
   ],
   "source": [
    "samples = [\"I'm the smartest student.\",\n",
    "          \"I'm the best student.\"]\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 10, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "binary_results = tokenizer.texts_to_matrix(samples, mode = 'binary')\n",
    "\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4bd7e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef761c60",
   "metadata": {},
   "source": [
    "테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ec8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"I'm the fastest student.\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88111e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index: {'<OOV>': 1, \"i'm\": 2, 'the': 3, 'student': 4, 'smartest': 5, 'best': 6}\n",
      "Test Text: [\"I'm the fastest student.\"]\n",
      "Test Sequence: [[2, 3, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(\"word_index:\", tokenizer.word_index)\n",
    "print(\"Test Text:\", test)\n",
    "print(\"Test Sequence:\", test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379dc78",
   "metadata": {},
   "source": [
    "## 원-핫 단어 벡터와 단어 임베딩\n",
    "\n",
    "- `원-핫 단어 벡터`\n",
    "  - 데이터가 희소(sparse)\n",
    "\n",
    "  - 고차원\n",
    "\n",
    "- `단어 임베딩`\n",
    "  - 밀집(dense)\n",
    "\n",
    "  - 저차원\n",
    "\n",
    "  <img src=\"https://freecontent.manning.com/wp-content/uploads/Chollet_DLfT_02.png\" width=\"400\">\n",
    "\n",
    "  <sub>출처: https://freecontent.manning.com/deep-learning-for-text/</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a4abc",
   "metadata": {},
   "source": [
    "## 단어 임베딩\n",
    "- 단어간 벡터사이의 **거리가 가까운**, 즉 비슷한 단어들끼리 임베딩\n",
    "\n",
    "- 거리 외에 임베딩 공간의 특정 방향도 의미를 가질 수 있음\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3010/1*OEmWDt4eztOcm5pr2QbxfA.png\">\n",
    "\n",
    "<sub>출처: https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8</sub>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf16df",
   "metadata": {},
   "source": [
    "## Embedding Layer\n",
    "\n",
    "- 특정 단어를 나타내는 정수 인덱스를 밀집 벡터(dense vector)로 매핑하는 딕셔너리 레이어\n",
    "\n",
    "- 입력: `(samples, sequence_length)`\n",
    "\n",
    "- 출력: `(samples, sequnece_length, dim)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6945d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172820cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdd2bbbb",
   "metadata": {},
   "source": [
    "## 예제 : IMDB 데이터\n",
    "\n",
    "- 인터넷 영화 데이터베이스(Internet Movie Database)\n",
    "\n",
    "- 양극단의 리뷰 5만개로 이루어진 데이터셋\n",
    "  - 훈련데이터: 25,000개\n",
    "  - 테스트데이터 : 25,000개\n",
    "\n",
    "  <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQlk-f2SHB6-Vs3RWwIugMctsyEn2QVZWC5KQ&usqp=CAU\">\n",
    "\n",
    "- https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb478598",
   "metadata": {},
   "source": [
    "### module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41520aff",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446914c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5eb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f0081a2",
   "metadata": {},
   "source": [
    "### 데이터 확인\n",
    "- 긍정: 1\n",
    "- 부정: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f0444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cb409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d6be1ea",
   "metadata": {},
   "source": [
    "### (참고) IMDB 데이터셋에서 가장 많이 사용된 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbe4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5f9816",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "- 모든 데이터를 같은 길이로 맞추기\n",
    "\n",
    "  - `pad_sequence()`\n",
    "    - 데이터가 maxlen보다 길면 데이터를 자름\n",
    "\n",
    "    - 데이터가 길면 `padding` 설정\n",
    "      - `pre`: 데이터 앞에 0으로 채움\n",
    "      -  `post`: 데이터 뒤에 0으로 채움\n",
    "\n",
    "\n",
    "- 모든 데이터(문장 하나하나)가 같은 길이로 맞춰저야 `Embedding` 레이어를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee3572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4816cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d66677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16003101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d29741",
   "metadata": {},
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f10fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c2f13b",
   "metadata": {},
   "source": [
    "### 모델 컴파일 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7e6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd04bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1f4bdfd",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48553912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd8216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6d714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e341a5",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6c21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deaf565d",
   "metadata": {},
   "source": [
    "### 단어의 수를 늘린 후 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1b1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d00d2f6f",
   "metadata": {},
   "source": [
    "데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9312bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a649a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f10c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a5eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d12ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc6db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b869482",
   "metadata": {},
   "source": [
    "위의 결과도 나쁘지 않으나 과적합이 되는 이유\n",
    "- 단어간 관계나 문장 구조 등 의미적 연결을 고려하지 않음\n",
    "\n",
    "- 시퀀스 전체를 고려한 특성을 학습하는 것은 `Embedding`층 위에 `RNN`층이나 `1D 합성곱`을 추가하는 것이 좋음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821065a",
   "metadata": {},
   "source": [
    "## 단어 임베딩의 종류\n",
    "- LSA\n",
    "\n",
    "- Word2Vec\n",
    "\n",
    "- GloVe\n",
    "\n",
    "- FastText\n",
    "\n",
    "- etc..\n",
    "\n",
    "<!-- ## 사전 훈련된 모델\n",
    "https://github.com/Hironsan/awesome-embedding-models#pre-trained-word-vectors -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e1065",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "- 2013년, Mikolov 와 동료들이 제안한 모형\n",
    "\n",
    "- 분류 등과 같이 별도의 레이블이 없이 텍스트 자체만 있어도 학습이 가능\n",
    "\n",
    "- Word2Vec의 방식  \n",
    "  주변 단어의 관계를 이용\n",
    "\n",
    "  - CBOW(continuous bag-of-words)\n",
    "    - 주변단어의 임베딩을 더해서 대상단어를 예측\n",
    "\n",
    "  - Skip-Gram\n",
    "    - 대상 단어의 임베딩으로 주변단어를 예측\n",
    "\n",
    "    - 일반적으로 CBOW보다 성능이 좋은 편\n",
    "\n",
    "    - 한번에 여러 단어를 예측해야하기 때문에 비효율적  \n",
    "      최근에는 **negative sampling**이라는 방법을 사용\n",
    "\n",
    "  <img src=\"https://www.researchgate.net/publication/328160770/figure/fig14/AS:679665089925122@1539056193562/CBOW-and-Skip-Gram-neural-architectures.ppm\">\n",
    "\n",
    "  <sub>출처: https://www.researchgate.net/figure/CBOW-and-Skip-Gram-neural-architectures_fig14_328160770</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8da50",
   "metadata": {},
   "source": [
    "### 구텐베르크 프로젝트 예제\n",
    "- 코드 출처 : http://doc.mindscale.kr/km/unstructured/11.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ee7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "224ada55",
   "metadata": {},
   "source": [
    "### 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cf36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c758e9ff",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fdb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54767339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d75a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680661a9",
   "metadata": {},
   "source": [
    "`gensim` 패키지로부터 WordVec을 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37148b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc32334",
   "metadata": {},
   "source": [
    "`sg` 인자에 0을 넘겨주면 CBOW, 1을 넘겨주면 Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ff465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15d92cf1",
   "metadata": {},
   "source": [
    "### 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5444c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770695e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e73f8251",
   "metadata": {},
   "source": [
    "### 단어를 벡터로 변환\n",
    "- `wv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139647d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfe51968",
   "metadata": {},
   "source": [
    "### 유추 또는 유비(analogy)\n",
    "- `wv.similarity()`에 두 단어를 넘겨주면 코사인 유사도를 구할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d745de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e965c2",
   "metadata": {},
   "source": [
    "- `wv.most_similar()`에 단어를 넘겨주면 가장 유사한 단어를 추출할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f9259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7b2a90",
   "metadata": {},
   "source": [
    "- `wv_most_similar()`에 `positive`와 `negative`라는 옵션을 넘길 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b17b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ca8c2c",
   "metadata": {},
   "source": [
    "### gensim으로 학습된 단어 임베딩을 Keras에서 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d08bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5498d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "618efc6d",
   "metadata": {},
   "source": [
    "### gensim으로 학습된 단어 임베딩을 케라스의 임베딩 레이어의 가중치로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee796d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce373e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0060c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba91ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb63b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce7fd6b",
   "metadata": {},
   "source": [
    "## Keras에서 Word2Vec 직접 학습\n",
    "- 코드 출처 : http://doc.mindscale.kr/km/unstructured/11.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792a03e",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825fdf85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caae054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ed3233",
   "metadata": {},
   "source": [
    "- 단어 번호와 단어의 관계를 사전으로 만듦\n",
    "\n",
    "- 1번은 문장의 시작, 2번은 사전에 없는 단어(OOV)로 미리 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ce879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90883932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814709f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8674e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea40c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4f1056",
   "metadata": {},
   "source": [
    "### 텍스트를 단어 번호로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33156404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35eaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "073391bd",
   "metadata": {},
   "source": [
    "- `Tokenizer`를 사용해 텍스트를 단어로 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e069854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a708f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f6560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee202ac5",
   "metadata": {},
   "source": [
    "### 단어쌍 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aac4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16de28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e935fc67",
   "metadata": {},
   "source": [
    "- 단어를 무작위로 추출하면 자주 나오는 단어가 더 많이 나오게됨\n",
    "\n",
    "- 이를 방지하기위해 단어를 추출할 확률의 균형을 맞춘 샘플링 표를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e07433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0452ab36",
   "metadata": {},
   "source": [
    "- 두 단어씩 뽑아 좌우 2단어(`window_size=2`)안에 들어있는 경우가 있는지 없는지 확인하여 데이터를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7817fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd493a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7e59dd8",
   "metadata": {},
   "source": [
    "- `labels`에는 윈도우 안에 들어있는 경우가 있으면 1, 없으면 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3126671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d37524d",
   "metadata": {},
   "source": [
    "- 대상 단어는 `word_context`으로, 맥락 단어는 `word_context`로 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2c794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "750bb60c",
   "metadata": {},
   "source": [
    "- 배열로 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387da2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8e98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2709bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f4c63ab",
   "metadata": {},
   "source": [
    "### Skip-gram 모형\n",
    "\n",
    "- Skip-gram 모형은 함수형 API를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254a192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fb79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c0b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28470a82",
   "metadata": {},
   "source": [
    "### 모델 컴파일 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5697ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76c2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f8e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3894af",
   "metadata": {},
   "source": [
    "### 임베딩 레이어 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b94889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753e0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6b9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64484059",
   "metadata": {},
   "source": [
    "- 임베딩 레이어 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a79386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f314965a",
   "metadata": {},
   "source": [
    "- 임베딩 레이어를 추가할때 `trainable`를 `False`로 하면 추가학습이 이루어 지지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2521bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec57c7eb",
   "metadata": {},
   "source": [
    "## 사전 훈련된 단어 임베딩 사용하기 : GloVe 임베딩\n",
    "\n",
    "- 코드 출처: 케라스 창시자에게 배우는 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e36d26",
   "metadata": {},
   "source": [
    "### 원본 IMDB 텍스트 내려받기\n",
    "- http://mng.bz/0tIo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a9031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874ea28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d30cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bc41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22268f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebeb52e4",
   "metadata": {},
   "source": [
    "### 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb81473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92c3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50433871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35476d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45df29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189562cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e0ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3d8cff",
   "metadata": {},
   "source": [
    "### GloVe 단어 임베딩 내려받기\n",
    "\n",
    "- https://nlp.stanford.edu/projects/glove\n",
    "\n",
    "- http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "- 시간 소요 (5~7m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed38ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9433572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9718b03b",
   "metadata": {},
   "source": [
    "### 임베딩 전처리\n",
    "- GloVe 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1fcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57da340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd2ff22",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bc5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34532105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18211f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d7819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddb75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a24d8602",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988945e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1baecc2e",
   "metadata": {},
   "source": [
    "## 사전 훈련된 단어 임베딩을 사용하지 않고 같은 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90373f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf3e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c6b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "894c50eb",
   "metadata": {},
   "source": [
    "### 테스트 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c586d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202aaae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f5748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc4a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94a748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
